\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@input{vorspann.aux}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\citation{lecun2015deep}
\citation{krizhevsky2012imagenet}
\citation{he2017mask}
\citation{zollhoefer2018state}
\citation{sun2017revisiting}
\citation{everingham2010pascal}
\citation{lin2014microsoft}
\citation{mildenhall2021nerf}
\citation{barron2021mip}
\citation{kerbl3Dgaussians}
\citation{fridovich2023k}
\citation{CutAndSplat2024}
\citation{tobin2017domain}
\citation{denninger2019blenderproc}
\citation{dwibedi2017cutpaste}
\citation{zanjani2025gaussian}
\citation{godard2017unsupervised}
\citation{bertasius2019maskprop}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{luiten2024dynamic}
\citation{yang2024deformable}
\citation{CutAndSplat2024}
\citation{mildenhall2021nerf}
\citation{mildenhall2021nerf}
\citation{mildenhall2021nerf}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Fundamentals}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Fundamentals}{{2}{3}{Fundamentals}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Neural Radiance Fields}{3}{section.2.1}\protected@file@percent }
\newlabel{sec:Fundamentals_NeRF}{{2.1}{3}{Neural Radiance Fields}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Core principle of NeRF: A model is optimized from input images and can subsequently generate novel views of the scene (after \cite  {mildenhall2021nerf}).}}{3}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:nerf_teaser}{{2.1}{3}{Core principle of NeRF: A model is optimized from input images and can subsequently generate novel views of the scene (after \cite {mildenhall2021nerf})}{figure.caption.3}{}}
\citation{mildenhall2021nerf}
\citation{mildenhall2021nerf}
\citation{kerbl3Dgaussians}
\citation{kerbl3Dgaussians}
\citation{kerbl3Dgaussians}
\citation{schoenberger2016mvs}
\citation{schoenberger2016sfm}
\citation{kerbl3Dgaussians}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces NeRF pipeline: The MLP maps 5D inputs to color and density, which are composed into an image via volumetric rendering (after \cite  {mildenhall2021nerf}).}}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:nerf_pipeline}{{2.2}{4}{NeRF pipeline: The MLP maps 5D inputs to color and density, which are composed into an image via volumetric rendering (after \cite {mildenhall2021nerf})}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Gaussian Splatting}{4}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Scene Representation with 3D Gaussians}{4}{subsection.2.2.1}\protected@file@percent }
\citation{zwicker2001ewa}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Optimization and rendering pipeline of Gaussian Splatting: The process begins with a sparse structure-from-motion (SfM) point cloud, which serves as the basis for creating an initial set of 3D Gaussian functions. These Gaussians are refined through iterative optimization, with their density adaptively controlled to ensure accurate scene representation. A fast tile-based rasterizer enables competitive rendering times compared to modern radiance field methods (figure from \cite  {kerbl3Dgaussians}).}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:overview}{{2.3}{5}{Optimization and rendering pipeline of Gaussian Splatting: The process begins with a sparse structure-from-motion (SfM) point cloud, which serves as the basis for creating an initial set of 3D Gaussian functions. These Gaussians are refined through iterative optimization, with their density adaptively controlled to ensure accurate scene representation. A fast tile-based rasterizer enables competitive rendering times compared to modern radiance field methods (figure from \cite {kerbl3Dgaussians})}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Rendering with 3D Gaussian Splatting}{5}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Projection of 3D Gaussians}{6}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Simplified Covariance Computation}{6}{section*.7}\protected@file@percent }
\newlabel{eq:calc_sigma}{{2.3}{6}{Simplified Covariance Computation}{equation.2.3}{}}
\citation{kerbl3Dgaussians}
\citation{kerbl3Dgaussians}
\citation{kerbl3Dgaussians}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Optimization}{7}{subsection.2.2.3}\protected@file@percent }
\newlabel{eq:loss_GS}{{2.4}{7}{Optimization}{equation.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Adaptive Control of 3D Gaussians}{7}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Differentiable Rasterizer}{7}{subsection.2.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Adaptive density control: The top row shows under-reconstruction, where small geometries (black outlines) are supplemented by cloning a Gaussian. The bottom row shows over-reconstruction, where a large Gaussian is split into two smaller ones (after \cite  {kerbl3Dgaussians}).}}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig:adaptivecontrol}{{2.4}{8}{Adaptive density control: The top row shows under-reconstruction, where small geometries (black outlines) are supplemented by cloning a Gaussian. The bottom row shows over-reconstruction, where a large Gaussian is split into two smaller ones (after \cite {kerbl3Dgaussians})}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Tile-based Rasterization Process}{8}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Rendering and Blending}{8}{section*.11}\protected@file@percent }
\newlabel{eq:projection_3D_gaussians}{{2.6}{9}{Rendering and Blending}{equation.2.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Backward Pass and Gradient Computation}{9}{section*.12}\protected@file@percent }
\citation{mildenhall2021nerf}
\citation{barron2021mip}
\citation{barron2023zipnerf}
\citation{kerbl3Dgaussians}
\citation{gaussian_grouping}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}State of the Art}{10}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Gaussian Splatting for Scene Representation}{10}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Dynamic Extensions of Gaussian Splatting}{10}{section.3.2}\protected@file@percent }
\citation{luiten2024dynamic}
\citation{stearnsmarbels}
\citation{yang2024deformable}
\citation{pumarola2021d}
\citation{yang2023gs4d}
\citation{lispacetimegaussianfeaturesplattingrealtime2024}
\citation{wu20244d}
\citation{fridovich2023k}
\citation{Dwibedi2017}
\citation{Tobin2017}
\citation{Liu2018}
\citation{Li2023MattingSurvey}
\citation{Denninger2019}
\citation{Lee2018}
\citation{Kirillov2023}
\citation{Bertasius2020}
\citation{Godard2019}
\citation{Niu2021}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Synthetic Compositing and Dataset Pipelines}{11}{section.3.3}\protected@file@percent }
\citation{InpaintingLimitations2019}
\citation{MonoDepthLimitations2018}
\citation{Kirillov2023}
\citation{MaskPropagation2019}
\citation{He2017MaskRCNN}
\citation{Detectron22020}
\citation{MaskPropagation2019}
\citation{zanjani2025gaussiansplattingeffectivedata}
\citation{SyntheticDrone2023}
\citation{SurgicalGS2023}
\citation{MobileRobotsGS2024}
\citation{CutAndSplat2024}
\citation{luiten2024dynamic}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Gaussian Splatting for Synthetic Dataset Generation}{12}{section.3.4}\protected@file@percent }
\citation{luiten2024dynamic}
\citation{luiten2024dynamic}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis}{13}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Scene Representation}{13}{section*.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Schematic illustration of the local rotation similarity loss in D3DGS~\cite  {luiten2024dynamic}.}}{13}{figure.caption.14}\protected@file@percent }
\newlabel{fig:loss_fig_luiten}{{3.1}{13}{Schematic illustration of the local rotation similarity loss in D3DGS~\cite {luiten2024dynamic}}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{Physical Regularization}{14}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Local Rigidity Loss}{14}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Local Rotation Similarity Loss}{14}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Isometry Loss}{14}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Optimization}{15}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Methodology}{16}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Pipeline A: Reconstruction of 3D and Dynamic 3D Models}{16}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Capture setup and calibration}{16}{subsection.4.1.1}\protected@file@percent }
\citation{luiten2024dynamic}
\citation{ravi2024sam2}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces  \textbf  {Overview of the proposed composition pipeline.} \textbf  {Pipeline A} converts multi-view captures into per-object 3DGS and D3DGS models via calibration, mask generation, and model training. \textbf  {Pipeline B} composes exported models into multi-object scenes, producing synchronized RGB, depth, segmentation, and occlusion annotations. }}{17}{figure.caption.20}\protected@file@percent }
\newlabel{fig:Ablauf}{{4.1}{17}{\textbf {Overview of the proposed composition pipeline.} \textbf {Pipeline A} converts multi-view captures into per-object 3DGS and D3DGS models via calibration, mask generation, and model training. \textbf {Pipeline B} composes exported models into multi-object scenes, producing synchronized RGB, depth, segmentation, and occlusion annotations}{figure.caption.20}{}}
\citation{kerbl3Dgaussians}
\citation{luiten2024dynamic}
\citation{xiang2024structured}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Data Preparation: Mask Generation and Prompt Propagation}{18}{subsection.4.1.2}\protected@file@percent }
\newlabel{sec:maskgen}{{4.1.2}{18}{Data Preparation: Mask Generation and Prompt Propagation}{subsection.4.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}3D / Dynamic-3D Gaussian Model Training}{18}{subsection.4.1.3}\protected@file@percent }
\newlabel{sec:modeltraining}{{4.1.3}{18}{3D / Dynamic-3D Gaussian Model Training}{subsection.4.1.3}{}}
\@writefile{toc}{\contentsline {paragraph}{External 3D assets.}{19}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Pipeline B: Composition and Synthetic Dataset Generation}{19}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Scene configuration and class indexing}{19}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Camera definition and interpolation}{19}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Placement duplication and motion handling}{20}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Mask rendering and mask types}{20}{subsection.4.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Occlusion scoring}{20}{section*.22}\protected@file@percent }
\citation{markley2007averaging}
\citation{Detectron22020}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}6D pose estimation}{21}{subsection.4.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.6}Keypoint detection and propagation}{22}{subsection.4.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.7}Rendered outputs and metadata}{22}{subsection.4.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{23}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Compositional Scene Generation}{23}{section.5.1}\protected@file@percent }
\citation{schoenberger2016sfm}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces  \textbf  {Compositional scene generation.} Example of multi-object scenes composed from independently reconstructed Gaussian Splatting models. Each row shows one scene configuration with RGB, depth, bounding boxes, and segmentation overlays. All semantic annotations are generated automatically and remain spatially consistent across views. }}{24}{figure.caption.23}\protected@file@percent }
\newlabel{fig:composition}{{5.1}{24}{\textbf {Compositional scene generation.} Example of multi-object scenes composed from independently reconstructed Gaussian Splatting models. Each row shows one scene configuration with RGB, depth, bounding boxes, and segmentation overlays. All semantic annotations are generated automatically and remain spatially consistent across views}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Multi-view Occlusion Handling}{24}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Scene Generalization}{24}{section.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces  \textbf  {Occlusion handling across views.} Segmentation overlays from front and side viewpoints of two interacting subjects. Even under strong mutual occlusion, instance masks remain consistent and well aligned with visible contours. }}{25}{figure.caption.24}\protected@file@percent }
\newlabel{fig:occlusion}{{5.2}{25}{\textbf {Occlusion handling across views.} Segmentation overlays from front and side viewpoints of two interacting subjects. Even under strong mutual occlusion, instance masks remain consistent and well aligned with visible contours}{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces  \textbf  {Scene generalization and recontextualization.} Dynamic subjects composited into a novel virtual environment reconstructed with COLMAP. The system maintains consistent geometry and segmentation alignment across domains, demonstrating flexible recontextualization of pre-trained Gaussian models. }}{25}{figure.caption.25}\protected@file@percent }
\newlabel{fig:generalization}{{5.3}{25}{\textbf {Scene generalization and recontextualization.} Dynamic subjects composited into a novel virtual environment reconstructed with COLMAP. The system maintains consistent geometry and segmentation alignment across domains, demonstrating flexible recontextualization of pre-trained Gaussian models}{figure.caption.25}{}}
\citation{Detectron22020}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces  \textbf  {Dynamic scene generation.} Representative time steps of a moving subject with RGB and segmentation overlays. The consistent motion and geometry across frames demonstrate temporally stable 4D rendering. }}{26}{figure.caption.26}\protected@file@percent }
\newlabel{fig:temporal}{{5.4}{26}{\textbf {Dynamic scene generation.} Representative time steps of a moving subject with RGB and segmentation overlays. The consistent motion and geometry across frames demonstrate temporally stable 4D rendering}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Temporal Consistency in Dynamic Scenes}{26}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Qualitative Pose Estimation}{26}{section.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces  \textbf  {Qualitative analysis of pose and keypoint propagation.} Four frames of a dynamic subject showing estimated object poses (top) and propagated keypoints (bottom). The coordinate systems evolve consistently over time, while keypoint trajectories remain coherent despite local misalignments. }}{27}{figure.caption.27}\protected@file@percent }
\newlabel{fig:keypoints}{{5.5}{27}{\textbf {Qualitative analysis of pose and keypoint propagation.} Four frames of a dynamic subject showing estimated object poses (top) and propagated keypoints (bottom). The coordinate systems evolve consistently over time, while keypoint trajectories remain coherent despite local misalignments}{figure.caption.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Keypoint Propagation}{27}{section.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Summary and Outlook}{28}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Summary of Key Findings}{28}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Limitations}{29}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Future Developments and Research Perspectives}{29}{section.6.3}\protected@file@percent }
\bibstyle{plain}
\bibcite{barron2021mip}{1}
\bibcite{barron2023zipnerf}{2}
\bibcite{MaskPropagation2019}{3}
\bibcite{bertasius2019maskprop}{4}
\bibcite{Bertasius2020}{5}
\bibcite{Denninger2019}{6}
\bibcite{denninger2019blenderproc}{7}
\bibcite{MobileRobotsGS2024}{8}
\bibcite{Dwibedi2017}{9}
\@writefile{toc}{\contentsline {chapter}{References}{31}{section.6.3}\protected@file@percent }
\newlabel{Sec:1}{{6.3}{31}{References}{section*.28}{}}
\bibcite{dwibedi2017cutpaste}{10}
\bibcite{everingham2010pascal}{11}
\bibcite{fridovich2023k}{12}
\bibcite{godard2017unsupervised}{13}
\bibcite{MonoDepthLimitations2018}{14}
\bibcite{Godard2019}{15}
\bibcite{He2017MaskRCNN}{16}
\bibcite{he2017mask}{17}
\bibcite{kerbl3Dgaussians}{18}
\bibcite{Kirillov2023}{19}
\bibcite{krizhevsky2012imagenet}{20}
\bibcite{lecun2015deep}{21}
\bibcite{Lee2018}{22}
\bibcite{Li2023MattingSurvey}{23}
\bibcite{lispacetimegaussianfeaturesplattingrealtime2024}{24}
\bibcite{lin2014microsoft}{25}
\bibcite{Liu2018}{26}
\bibcite{luiten2024dynamic}{27}
\bibcite{markley2007averaging}{28}
\bibcite{mildenhall2021nerf}{29}
\bibcite{Niu2021}{30}
\bibcite{pumarola2021d}{31}
\bibcite{ravi2024sam2}{32}
\bibcite{schoenberger2016sfm}{33}
\bibcite{schoenberger2016mvs}{34}
\bibcite{stearnsmarbels}{35}
\bibcite{SyntheticDrone2023}{36}
\bibcite{sun2017revisiting}{37}
\bibcite{Tobin2017}{38}
\bibcite{tobin2017domain}{39}
\bibcite{CutAndSplat2024}{40}
\bibcite{wu20244d}{41}
\bibcite{Detectron22020}{42}
\bibcite{xiang2024structured}{43}
\bibcite{yang2023gs4d}{44}
\bibcite{yang2024deformable}{45}
\bibcite{gaussian_grouping}{46}
\bibcite{InpaintingLimitations2019}{47}
\bibcite{zanjani2025gaussiansplattingeffectivedata}{48}
\bibcite{zanjani2025gaussian}{49}
\bibcite{SurgicalGS2023}{50}
\bibcite{zollhoefer2018state}{51}
\bibcite{zwicker2001ewa}{52}
\csname bt@set@cnt\endcsname{52}
\gdef \@abspage@last{41}
