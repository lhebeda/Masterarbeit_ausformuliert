\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@input{vorspann.aux}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\citation{lecun2015deep}
\citation{krizhevsky2012imagenet}
\citation{he2017mask}
\citation{zollhoefer2018state}
\citation{sun2017revisiting}
\citation{everingham2010pascal}
\citation{lin2014microsoft}
\citation{mildenhall2021nerf}
\citation{barron2021mip}
\citation{kerbl3Dgaussians}
\citation{fridovich2023k}
\citation{CutAndSplat2024}
\citation{tobin2017domain}
\citation{denninger2019blenderproc}
\citation{dwibedi2017cutpaste}
\citation{zanjani2025gaussian}
\citation{godard2017unsupervised}
\citation{bertasius2019maskprop}
\citation{luiten2024dynamic}
\citation{yang2024deformable}
\citation{CutAndSplat2024}
\@writefile{toc}{\contentsline {section}{\numberline {0.1}Introduction}{1}{section.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.1}Motivation}{1}{subsection.0.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.2}Structure of the Work}{2}{subsection.0.1.2}\protected@file@percent }
\citation{mildenhall2021nerf}
\citation{mildenhall2021nerf}
\citation{mildenhall2021nerf}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Fundamentals}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Fundamentals}{{1}{3}{Fundamentals}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Neural Radiance Fields}{3}{section.1.1}\protected@file@percent }
\newlabel{sec:Fundamentals_NeRF}{{1.1}{3}{Neural Radiance Fields}{section.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Core principle of NeRF: A model is optimized from input images and can subsequently generate novel views of the scene (after \cite  {mildenhall2021nerf}).}}{3}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:nerf_teaser}{{1.1}{3}{Core principle of NeRF: A model is optimized from input images and can subsequently generate novel views of the scene (after \cite {mildenhall2021nerf})}{figure.caption.3}{}}
\citation{mildenhall2021nerf}
\citation{mildenhall2021nerf}
\citation{kerbl3Dgaussians}
\citation{kerbl3Dgaussians}
\citation{kerbl3Dgaussians}
\citation{schoenberger2016mvs}
\citation{schoenberger2016sfm}
\citation{kerbl3Dgaussians}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces NeRF pipeline: The MLP maps 5D inputs to color and density, which are composed into an image via volumetric rendering (after \cite  {mildenhall2021nerf}).}}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:nerf_pipeline}{{1.2}{4}{NeRF pipeline: The MLP maps 5D inputs to color and density, which are composed into an image via volumetric rendering (after \cite {mildenhall2021nerf})}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Gaussian Splatting}{4}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Scene Representation with 3D Gaussians}{4}{subsection.1.2.1}\protected@file@percent }
\citation{zwicker2001ewa}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Optimization and rendering pipeline of Gaussian Splatting: The process begins with a sparse structure-from-motion (SfM) point cloud, which serves as the basis for creating an initial set of 3D Gaussian functions. These Gaussians are refined through iterative optimization, with their density adaptively controlled to ensure accurate scene representation. A fast tile-based rasterizer enables competitive rendering times compared to modern radiance field methods (figure from \cite  {kerbl3Dgaussians}).}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:overview}{{1.3}{5}{Optimization and rendering pipeline of Gaussian Splatting: The process begins with a sparse structure-from-motion (SfM) point cloud, which serves as the basis for creating an initial set of 3D Gaussian functions. These Gaussians are refined through iterative optimization, with their density adaptively controlled to ensure accurate scene representation. A fast tile-based rasterizer enables competitive rendering times compared to modern radiance field methods (figure from \cite {kerbl3Dgaussians})}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Rendering with 3D Gaussian Splatting}{5}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Projection of 3D Gaussians}{6}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Simplified Covariance Computation}{6}{section*.7}\protected@file@percent }
\newlabel{eq:calc_sigma}{{1.3}{6}{Simplified Covariance Computation}{equation.1.3}{}}
\citation{kerbl3Dgaussians}
\citation{kerbl3Dgaussians}
\citation{kerbl3Dgaussians}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Optimization}{7}{subsection.1.2.3}\protected@file@percent }
\newlabel{eq:loss_GS}{{1.4}{7}{Optimization}{equation.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Adaptive Control of 3D Gaussians}{7}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Differentiable Rasterizer}{7}{subsection.1.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Adaptive density control: The top row shows under-reconstruction, where small geometries (black outlines) are supplemented by cloning a Gaussian. The bottom row shows over-reconstruction, where a large Gaussian is split into two smaller ones (after \cite  {kerbl3Dgaussians}).}}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig:adaptivecontrol}{{1.4}{8}{Adaptive density control: The top row shows under-reconstruction, where small geometries (black outlines) are supplemented by cloning a Gaussian. The bottom row shows over-reconstruction, where a large Gaussian is split into two smaller ones (after \cite {kerbl3Dgaussians})}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Tile-based Rasterization Process}{8}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Rendering and Blending}{8}{section*.11}\protected@file@percent }
\newlabel{eq:projection_3D_gaussians}{{1.6}{9}{Rendering and Blending}{equation.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Backward Pass and Gradient Computation}{9}{section*.12}\protected@file@percent }
\citation{mildenhall2021nerf}
\citation{barron2021mip}
\citation{barron2023zipnerf}
\citation{kerbl3Dgaussians}
\citation{gaussian_grouping}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}State of the Art}{10}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Gaussian Splatting for Scene Representation}{10}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Dynamic Extensions of Gaussian Splatting}{10}{section.2.2}\protected@file@percent }
\citation{luiten2024dynamic}
\citation{stearnsmarbels}
\citation{yang2024deformable}
\citation{pumarola2021d}
\citation{yang2023gs4d}
\citation{lispacetimegaussianfeaturesplattingrealtime2024}
\citation{wu20244d}
\citation{fridovich2023k}
\citation{luiten2024dynamic}
\citation{yang2023gs4d}
\citation{Dwibedi2017}
\citation{Tobin2017}
\citation{Liu2018}
\citation{Li2023MattingSurvey}
\citation{Denninger2019}
\citation{Lee2018}
\citation{Kirillov2023}
\citation{Bertasius2020}
\citation{Godard2019}
\citation{Niu2021}
\citation{InpaintingLimitations2019}
\citation{MonoDepthLimitations2018}
\citation{Kirillov2023}
\citation{MaskPropagation2019}
\citation{He2017MaskRCNN}
\citation{Detectron22020}
\citation{MaskPropagation2019}
\citation{zanjani2025gaussiansplattingeffectivedata}
\citation{SyntheticDrone2023}
\citation{SurgicalGS2023}
\citation{MobileRobotsGS2024}
\citation{CutAndSplat2024}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Synthetic Compositing and Dataset Pipelines}{12}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Gaussian Splatting for Synthetic Dataset Generation}{12}{section.2.4}\protected@file@percent }
\citation{luiten2024dynamic}
\citation{yang2023gs4d}
\citation{yang2023gs4d}
\citation{yang2023gs4d}
\citation{yang2023gs4d}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Detailed Review of Prominent Dynamic GS Methods}{13}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting}{13}{subsection.2.5.1}\protected@file@percent }
\newlabel{sec:Real-Time4dgs}{{2.5.1}{13}{Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting}{subsection.2.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Extension of the Rendering Equation}{13}{section*.14}\protected@file@percent }
\citation{kerbl3Dgaussians}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The rendering pipeline of the proposed 4DGS method. For a given time \(t\) and view \(I\), each 4D Gaussian is decomposed into a conditional 3D Gaussian and a marginal 1D Gaussian. The conditional 3D Gaussian is then projected onto a 2D splat. Finally, the planar conditional Gaussian, the 1D marginal Gaussian, and the temporally varying, view-dependent color are combined to render the view \(I\) (figure adapted from \cite  {yang2023gs4d}).}}{14}{figure.caption.13}\protected@file@percent }
\newlabel{fig:pipeline_real_time_4D}{{2.1}{14}{The rendering pipeline of the proposed 4DGS method. For a given time \(t\) and view \(I\), each 4D Gaussian is decomposed into a conditional 3D Gaussian and a marginal 1D Gaussian. The conditional 3D Gaussian is then projected onto a 2D splat. Finally, the planar conditional Gaussian, the 1D marginal Gaussian, and the temporally varying, view-dependent color are combined to render the view \(I\) (figure adapted from \cite {yang2023gs4d})}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{Scene Representation with 4D Gaussians}{14}{section*.15}\protected@file@percent }
\newlabel{eq:rotation_matrix}{{2.3}{14}{Scene Representation with 4D Gaussians}{equation.2.3}{}}
\citation{luiten2024dynamic}
\@writefile{toc}{\contentsline {subsubsection}{Projection onto the Image Plane}{15}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Spherical Harmonics for Color Representation}{15}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis}{15}{section.2.6}\protected@file@percent }
\citation{luiten2024dynamic}
\citation{luiten2024dynamic}
\@writefile{toc}{\contentsline {subsubsection}{Scene Representation}{16}{section*.18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Schematic illustration of the local rotation similarity loss in D3DGS~\cite  {luiten2024dynamic}.}}{16}{figure.caption.19}\protected@file@percent }
\newlabel{fig:loss_fig_luiten}{{2.2}{16}{Schematic illustration of the local rotation similarity loss in D3DGS~\cite {luiten2024dynamic}}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{Physical Regularization}{16}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Local Rigidity Loss}{16}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Local Rotation Similarity Loss}{17}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Isometry Loss}{17}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Optimization}{17}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{18}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Model Training}{18}{section.3.1}\protected@file@percent }
\newlabel{sec:modeltraining}{{3.1}{18}{Model Training}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Data Preparation}{18}{subsection.3.1.1}\protected@file@percent }
\newlabel{sec:data_preparation}{{3.1.1}{18}{Data Preparation}{subsection.3.1.1}{}}
\citation{kerbl3Dgaussians}
\@writefile{toc}{\contentsline {subsubsection}{OpenCV Calibration}{19}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}3D Gaussian Splatting}{19}{subsection.3.1.2}\protected@file@percent }
\citation{yang20244dgs}
\citation{yuan20251000fps4dgaussian}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}4D Gaussian Splatting}{20}{subsection.3.1.3}\protected@file@percent }
\newlabel{sec:4dgs}{{3.1.3}{20}{4D Gaussian Splatting}{subsection.3.1.3}{}}
\citation{luiten2024dynamic}
\citation{luiten2024dynamic}
\citation{ravi2024sam2}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Dynamic 3D Gaussian Splatting}{21}{subsection.3.1.4}\protected@file@percent }
\newlabel{sec:method_dynamic3d}{{3.1.4}{21}{Dynamic 3D Gaussian Splatting}{subsection.3.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Dataset Preparation and Mask Generation}{21}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Training Adjustments}{22}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Composition Pipeline}{22}{section.3.2}\protected@file@percent }
\newlabel{sec:compositionpipeline}{{3.2}{22}{Composition Pipeline}{section.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces  \textbf  {Overview of the proposed composition pipeline.} \textbf  {Pipeline A} converts multi-view captures into per-object 3DGS and D3DGS models via calibration, mask generation, and model training. \textbf  {Pipeline B} composes exported models into multi-object scenes, producing synchronized RGB, depth, segmentation, and occlusion annotations. }}{23}{figure.caption.28}\protected@file@percent }
\newlabel{fig:Ablauf}{{3.1}{23}{\textbf {Overview of the proposed composition pipeline.} \textbf {Pipeline A} converts multi-view captures into per-object 3DGS and D3DGS models via calibration, mask generation, and model training. \textbf {Pipeline B} composes exported models into multi-object scenes, producing synchronized RGB, depth, segmentation, and occlusion annotations}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Pipeline A: Reconstruction of 3D and Dynamic 3D Models}{23}{section.3.3}\protected@file@percent }
\citation{luiten2024dynamic}
\citation{ravi2024sam2}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Capture setup and calibration}{24}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Data Preparation: Mask Generation and Prompt Propagation}{24}{subsection.3.3.2}\protected@file@percent }
\newlabel{sec:maskgen}{{3.3.2}{24}{Data Preparation: Mask Generation and Prompt Propagation}{subsection.3.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Pipeline B: Composition and Synthetic Dataset Generation}{25}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Scene configuration and class indexing}{25}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Camera definition and interpolation}{25}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Placement duplication and motion handling}{26}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Mask rendering and mask types}{26}{subsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Occlusion scoring}{26}{section*.29}\protected@file@percent }
\citation{markley2007averaging}
\citation{Detectron22020}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}6D pose estimation}{27}{subsection.3.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.6}Keypoint detection and propagation}{28}{subsection.3.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.7}Rendered outputs and metadata}{28}{subsection.3.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{29}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Compositional Scene Generation}{29}{section.4.1}\protected@file@percent }
\citation{schoenberger2016sfm}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces  \textbf  {Compositional scene generation.} Example of multi-object scenes composed from independently reconstructed Gaussian Splatting models. Each row shows one scene configuration with RGB, depth, bounding boxes, and segmentation overlays. All semantic annotations are generated automatically and remain spatially consistent across views. }}{30}{figure.caption.30}\protected@file@percent }
\newlabel{fig:composition}{{4.1}{30}{\textbf {Compositional scene generation.} Example of multi-object scenes composed from independently reconstructed Gaussian Splatting models. Each row shows one scene configuration with RGB, depth, bounding boxes, and segmentation overlays. All semantic annotations are generated automatically and remain spatially consistent across views}{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Multi-view Occlusion Handling}{30}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Scene Generalization}{30}{section.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces  \textbf  {Occlusion handling across views.} Segmentation overlays from front and side viewpoints of two interacting subjects. Even under strong mutual occlusion, instance masks remain consistent and well aligned with visible contours. }}{31}{figure.caption.31}\protected@file@percent }
\newlabel{fig:occlusion}{{4.2}{31}{\textbf {Occlusion handling across views.} Segmentation overlays from front and side viewpoints of two interacting subjects. Even under strong mutual occlusion, instance masks remain consistent and well aligned with visible contours}{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces  \textbf  {Scene generalization and recontextualization.} Dynamic subjects composited into a novel virtual environment reconstructed with COLMAP. The system maintains consistent geometry and segmentation alignment across domains, demonstrating flexible recontextualization of pre-trained Gaussian models. }}{31}{figure.caption.32}\protected@file@percent }
\newlabel{fig:generalization}{{4.3}{31}{\textbf {Scene generalization and recontextualization.} Dynamic subjects composited into a novel virtual environment reconstructed with COLMAP. The system maintains consistent geometry and segmentation alignment across domains, demonstrating flexible recontextualization of pre-trained Gaussian models}{figure.caption.32}{}}
\citation{Detectron22020}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces  \textbf  {Dynamic scene generation.} Representative time steps of a moving subject with RGB and segmentation overlays. The consistent motion and geometry across frames demonstrate temporally stable 4D rendering. }}{32}{figure.caption.33}\protected@file@percent }
\newlabel{fig:temporal}{{4.4}{32}{\textbf {Dynamic scene generation.} Representative time steps of a moving subject with RGB and segmentation overlays. The consistent motion and geometry across frames demonstrate temporally stable 4D rendering}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Temporal Consistency in Dynamic Scenes}{32}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Qualitative Pose Estimation}{32}{section.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces  \textbf  {Qualitative analysis of pose and keypoint propagation.} Four frames of a dynamic subject showing estimated object poses (top) and propagated keypoints (bottom). The coordinate systems evolve consistently over time, while keypoint trajectories remain coherent despite local misalignments. }}{33}{figure.caption.34}\protected@file@percent }
\newlabel{fig:keypoints}{{4.5}{33}{\textbf {Qualitative analysis of pose and keypoint propagation.} Four frames of a dynamic subject showing estimated object poses (top) and propagated keypoints (bottom). The coordinate systems evolve consistently over time, while keypoint trajectories remain coherent despite local misalignments}{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Keypoint Propagation}{33}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Summary and Outlook}{34}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Summary of Key Findings}{34}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Limitations}{35}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Future Developments and Research Perspectives}{35}{section.5.3}\protected@file@percent }
\bibstyle{plain}
\bibcite{barron2021mip}{1}
\bibcite{barron2023zipnerf}{2}
\bibcite{MaskPropagation2019}{3}
\bibcite{bertasius2019maskprop}{4}
\bibcite{Bertasius2020}{5}
\bibcite{Denninger2019}{6}
\bibcite{denninger2019blenderproc}{7}
\bibcite{MobileRobotsGS2024}{8}
\bibcite{Dwibedi2017}{9}
\@writefile{toc}{\contentsline {chapter}{References}{37}{section.5.3}\protected@file@percent }
\newlabel{Sec:1}{{5.3}{37}{References}{section*.35}{}}
\bibcite{dwibedi2017cutpaste}{10}
\bibcite{everingham2010pascal}{11}
\bibcite{fridovich2023k}{12}
\bibcite{godard2017unsupervised}{13}
\bibcite{MonoDepthLimitations2018}{14}
\bibcite{Godard2019}{15}
\bibcite{He2017MaskRCNN}{16}
\bibcite{he2017mask}{17}
\bibcite{kerbl3Dgaussians}{18}
\bibcite{Kirillov2023}{19}
\bibcite{krizhevsky2012imagenet}{20}
\bibcite{lecun2015deep}{21}
\bibcite{Lee2018}{22}
\bibcite{Li2023MattingSurvey}{23}
\bibcite{lispacetimegaussianfeaturesplattingrealtime2024}{24}
\bibcite{lin2014microsoft}{25}
\bibcite{Liu2018}{26}
\bibcite{luiten2024dynamic}{27}
\bibcite{markley2007averaging}{28}
\bibcite{mildenhall2021nerf}{29}
\bibcite{Niu2021}{30}
\bibcite{pumarola2021d}{31}
\bibcite{ravi2024sam2}{32}
\bibcite{schoenberger2016sfm}{33}
\bibcite{schoenberger2016mvs}{34}
\bibcite{stearnsmarbels}{35}
\bibcite{SyntheticDrone2023}{36}
\bibcite{sun2017revisiting}{37}
\bibcite{Tobin2017}{38}
\bibcite{tobin2017domain}{39}
\bibcite{CutAndSplat2024}{40}
\bibcite{wu20244d}{41}
\bibcite{Detectron22020}{42}
\bibcite{yang2023gs4d}{43}
\bibcite{yang2024deformable}{44}
\bibcite{gaussian_grouping}{45}
\bibcite{InpaintingLimitations2019}{46}
\bibcite{yuan20251000fps4dgaussian}{47}
\bibcite{zanjani2025gaussiansplattingeffectivedata}{48}
\bibcite{zanjani2025gaussian}{49}
\bibcite{SurgicalGS2023}{50}
\bibcite{zollhoefer2018state}{51}
\bibcite{zwicker2001ewa}{52}
\csname bt@set@cnt\endcsname{52}
\gdef \@abspage@last{47}
